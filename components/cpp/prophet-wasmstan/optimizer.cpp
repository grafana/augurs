// Implementation of the `optimizer` interface found in the
// `prophet_wasmstan.wit` file. This effectively:
// - converts the inputs to the interface into something that Stan can
// understand,
//   using a `stan::io::array_var_context` to hold data and initial parameters
//   for Stan
// - uses the `model.hpp` file generated by `stanc` to create a new model with
// that data
//   and optimize it using the relevant class from `stan::services::optimize`,
//   passing it a `structured_writer` to write the output to (rather than a file
//   writer, which is what Stan does in normal usage)
// - converts the output of the optimization into a format matching the WIT
// interface.

#include "prophet_wasmstan.h"
#include <chrono>
#include <iostream>
#include <sstream>
#include <stdlib.h>
#include <string>
#include <vector>

#include "model/model.hpp"
#include "structured_writer.cpp"
#include <stan/callbacks/interrupt.hpp>
#include <stan/callbacks/logger.hpp>
#include <stan/callbacks/stream_logger.hpp>
#include <stan/io/array_var_context.hpp>
#include <stan/io/var_context.hpp>
#include <stan/model/model_base.hpp>
#include <stan/services/optimize/bfgs.hpp>
#include <stan/services/optimize/lbfgs.hpp>
#include <stan/services/optimize/newton.hpp>

// Convert the input data into a `stan::io::array_var_context` which can be used
// to create a Stan model.
stan::io::array_var_context
data_context(exports_augurs_prophet_wasmstan_optimizer_data_t *data) {
  using size_vec = std::vector<size_t>;
  // Create the var context. There's a constructor which accepts
  // two sets of three vectors: the first set defines the names,
  // values and dimensions of the `double` type data, while the
  // second is similar for the `int` type data.
  std::vector<std::string> names_r = {
      "y",        // Time series.
      "t",        // Timestamps.
      "cap",      // Capacities for logistic trend.
      "t_change", // Times of trend changepoints.
      "X",        // Regressors.
      "sigmas",   // Scale on seasonality prior.
      "tau",      // Scale on changepoints prior.
  };
  std::vector<double> values_r;
  // We can't use range based for loops here because these aren't
  // vectors, they're just pointers to C-style arrays.
  values_r.reserve(data->y.len + data->t.len + data->cap.len +
                   data->t_change.len + data->x.len + data->sigmas.len +
                   1); // Add one for tau.
  for (size_t i = 0; i < data->y.len; i++) {
    values_r.push_back(data->y.ptr[i]);
  }
  for (size_t i = 0; i < data->t.len; i++) {
    values_r.push_back(data->t.ptr[i]);
  }
  for (size_t i = 0; i < data->cap.len; i++) {
    values_r.push_back(data->cap.ptr[i]);
  }
  for (size_t i = 0; i < data->t_change.len; i++) {
    values_r.push_back(data->t_change.ptr[i]);
  }
  for (size_t i = 0; i < data->x.len; i++) {
    values_r.push_back(data->x.ptr[i]);
  }
  for (size_t i = 0; i < data->sigmas.len; i++) {
    values_r.push_back(data->sigmas.ptr[i]);
  }
  values_r.push_back(data->tau);
  std::vector<size_vec> dims_r{
      size_vec{data->y.len},                                      // y
      size_vec{data->t.len},                                      // t
      size_vec{data->cap.len},                                    // cap
      size_vec{data->t_change.len},                               // t_change
      size_vec{data->y.len, static_cast<unsigned long>(data->k)}, // X
      size_vec{data->sigmas.len},                                 // sigmas
      size_vec{},                                                 // tau
  };

  std::vector<std::string> names_i = {
      "T", // Number of time periods.
      "S", // Number of changepoints.
      "K", // Number of regressors.
      "trend_indicator",
      "s_a", // Indicator of additive features.
      "s_m", // Indicator of multiplicative features.
  };
  std::vector<int> values_i;
  values_i.reserve(names_i.size());
  // This is `T` in the STAN model definition but WIT identifiers
  // must be lower-kebab-case so we used `n` instead.
  values_i.push_back(data->n);
  values_i.push_back(data->s);
  values_i.push_back(data->k);
  values_i.push_back(data->trend_indicator);
  for (size_t i = 0; i < data->s_a.len; i++) {
    values_i.push_back(data->s_a.ptr[i]);
  }
  for (size_t i = 0; i < data->s_m.len; i++) {
    values_i.push_back(data->s_m.ptr[i]);
  }
  std::vector<size_vec> dims_i{size_vec{},               // T
                               size_vec{},               // S
                               size_vec{},               // K
                               size_vec{},               // trend_indicator
                               size_vec{data->s_a.len},  // s_a
                               size_vec{data->s_m.len}}; // s_m

  return stan::io::array_var_context(names_r, values_r, dims_r, names_i,
                                     values_i, dims_i);
}

// Convert the input parameters into a `stan::io::array_var_context` which can
// be used to optimize a Stan model.
stan::io::array_var_context
init_context(exports_augurs_prophet_wasmstan_optimizer_inits_t *inits) {
  using size_vec = std::vector<size_t>;

  std::vector<std::string> names = {
      "k",         // Base trend growth rate
      "m",         // Trend offset
      "delta",     // Trend rate adjustments
      "beta",      // Regressor coefficients
      "sigma_obs", // Observation noise
  };
  std::vector<double> values;
  values.reserve(inits->delta.len + inits->beta.len + 3);
  values.push_back(inits->k);
  values.push_back(inits->m);
  for (size_t i = 0; i < inits->delta.len; i++) {
    values.push_back(inits->delta.ptr[i]);
  }
  for (size_t i = 0; i < inits->beta.len; i++) {
    values.push_back(inits->beta.ptr[i]);
  }
  values.push_back(inits->sigma_obs);
  std::vector<size_vec> dims{
      size_vec{},                 // k
      size_vec{},                 // m
      size_vec{inits->delta.len}, // delta
      size_vec{inits->beta.len},  // beta
      size_vec{},                 // sigma_obs
  };

  return stan::io::array_var_context(names, values, dims);
}

// Args to the Newton optimizer.
struct NewtonArgs {
  int seed;
  int chain = 1;
  double init_radius = 2.0;
  int iter = 2000;

  // Constructor for the default values.
  NewtonArgs() {}

  // Constructor with optional overrides.
  NewtonArgs(exports_augurs_prophet_wasmstan_optimizer_optimize_opts_t *opts) {
    if (opts->seed.is_some) {
      seed = opts->seed.val;
    }
    if (opts->chain.is_some) {
      chain = opts->chain.val;
    };
    // if (opts->init_radius.is_some) {
    //   init_radius = opts->init_radius.val;
    // };
    if (opts->iter.is_some) {
      iter = opts->iter.val;
    };
    // if (opts->refresh.is_some) {
    //   refresh = opts->refresh.val;
    // };
  }
};

// Args to the LBFGS optimizer.
//
// Also used for the BFGS optimizer.
struct LBFGSArgs {
  int seed;
  int chain = 1;
  double init_radius = 2.0;
  double init_alpha = 0.001;
  double tol_obj = 1e-12;
  double tol_rel_obj = 10000;
  double tol_grad = 1e-08;
  double tol_rel_grad = 1e07;
  double tol_param = 1e-08;
  int iter = 2000;
  int refresh = 100;
  // Only applies for LBFGS, not BFGS.
  double history_size = 5;

  // Constructor for the default values.
  LBFGSArgs() {}

  // Constructor with optional overrides.
  LBFGSArgs(exports_augurs_prophet_wasmstan_optimizer_optimize_opts_t *opts) {
    if (opts->seed.is_some) {
      seed = opts->seed.val;
    }
    if (opts->chain.is_some) {
      chain = opts->chain.val;
    };
    // if (opts->init_radius.is_some) {
    //   init_radius = opts->init_radius.val;
    // };
    if (opts->history_size.is_some) {
      history_size = opts->history_size.val;
    };
    if (opts->init_alpha.is_some) {
      init_alpha = opts->init_alpha.val;
    };
    if (opts->tol_obj.is_some) {
      tol_obj = opts->tol_obj.val;
    };
    if (opts->tol_rel_obj.is_some) {
      tol_rel_obj = opts->tol_rel_obj.val;
    };
    if (opts->tol_grad.is_some) {
      tol_grad = opts->tol_grad.val;
    };
    if (opts->tol_rel_grad.is_some) {
      tol_rel_grad = opts->tol_rel_grad.val;
    };
    if (opts->tol_param.is_some) {
      tol_param = opts->tol_param.val;
    };
    if (opts->iter.is_some) {
      iter = opts->iter.val;
    };
    if (opts->refresh.is_some) {
      refresh = opts->refresh.val;
    };
  }

  void log(stan::callbacks::stream_logger &logger) {
    std::stringstream message;
    message << "method = optimize" << std::endl;
    message << "  optimize" << std::endl;
    message << "    algorithm = lbfgs" << std::endl;
    message << "      lbfgs" << std::endl;
    message << "        init_alpha = " << init_alpha << std::endl;
    message << "        tol_obj = " << tol_obj << std::endl;
    message << "        tol_rel_obj = " << tol_rel_obj << std::endl;
    message << "        tol_grad = " << tol_grad << std::endl;
    message << "        tol_rel_grad = " << tol_rel_grad << std::endl;
    message << "        tol_param = " << tol_param << std::endl;
    message << "        history_size = " << history_size << std::endl;
    message << "    jacobian = 0" << std::endl;
    message << "    iter = " << iter << std::endl;
    message << "    save_iterations = 0" << std::endl;
    message << "id = " << chain << std::endl;
    message << "random" << std::endl;
    message << "  seed = " << seed << std::endl;
    logger.debug(message);
  }
};

// Extract the parameter values from the list of names and values.
//
// The parameter writer just writes parameters to vectors of strings
// and doubles respectively, so we need to turn those into something
// more structured.
bool store_optimized_params(
    std::vector<std::string> &names, std::vector<double> &values,
    augurs_prophet_wasmstan_types_optimized_params_t *ret,
    prophet_wasmstan_string_t *err) {
  std::vector<double> beta;
  std::vector<double> delta;
  std::vector<double> trend;
  std::vector<int> beta_indices;
  std::vector<int> delta_indices;
  std::vector<int> trend_indices;
  for (size_t i = 0; i < names.size(); i++) {
    if (names[i] == "k") {
      ret->k = values[i];
    }
    if (names[i] == "m") {
      ret->m = values[i];
    }
    if (names[i] == "sigma_obs") {
      ret->sigma_obs = values[i];
    }
    if (names[i].substr(0, 4) == "beta") {
      int index = std::stoi(names[i].substr(5));
      beta.push_back(values[i]);
      // Indexes are 1-indexed in the STAN model so subtract 1.
      beta_indices.push_back(index - 1);
    }
    if (names[i].substr(0, 5) == "delta") {
      int index = std::stoi(names[i].substr(6));
      delta.push_back(values[i]);
      // Indexes are 1-indexed in the STAN model so subtract 1.
      delta_indices.push_back(index - 1);
    }
    if (names[i].substr(0, 5) == "trend") {
      int index = std::stoi(names[i].substr(6));
      trend.push_back(values[i]);
      // Indexes are 1-indexed in the STAN model so subtract 1.
      trend_indices.push_back(index - 1);
    }
  }
  ret->beta.len = beta.size();
  ret->delta.len = delta.size();
  ret->trend.len = trend.size();

  ret->beta.ptr = (double *)malloc(sizeof(double) * beta.size());
  if (ret->beta.ptr == NULL) {
    prophet_wasmstan_string_set(err, "Memory allocation failed for beta");
    return false;
  }
  for (size_t i = 0; i < beta.size(); i++) {
    ret->beta.ptr[i] = beta[beta_indices[i]];
  }

  ret->delta.ptr = (double *)malloc(sizeof(double) * delta.size());
  if (ret->delta.ptr == NULL) {
    prophet_wasmstan_string_set(err, "Memory allocation failed for delta");
    return false;
  }
  for (size_t i = 0; i < delta.size(); i++) {
    ret->delta.ptr[i] = delta[delta_indices[i]];
  }

  ret->trend.ptr = (double *)malloc(sizeof(double) * trend.size());
  if (ret->trend.ptr == NULL) {
    prophet_wasmstan_string_set(err, "Memory allocation failed for trend");
    return false;
  }
  for (size_t i = 0; i < trend.size(); i++) {
    ret->trend.ptr[i] = trend[trend_indices[i]];
  }
  return true;
}

// Optimize a Prophet model using Stan.
//
// This satisfies the `optimize` interface from the `prophet_wasmstan.wit` file.
// The `prophet_wasmstan.h` file generated by `wit-bindgen` contains the
// declaration of this function; if the interface is updated, the header file
// can be updated by running `just generate-lib-skeleton`, then this
// implementation will need updating too.
bool exports_augurs_prophet_wasmstan_optimizer_optimize(
    exports_augurs_prophet_wasmstan_optimizer_inits_t *init,
    exports_augurs_prophet_wasmstan_optimizer_data_t *data,
    exports_augurs_prophet_wasmstan_optimizer_optimize_opts_t *opts,
    exports_augurs_prophet_wasmstan_optimizer_optimize_output_t *ret,
    prophet_wasmstan_string_t *err) {

  // Write all logs to a single stream for now.
  std::stringstream debug;
  std::stringstream info;
  std::stringstream warn;
  std::stringstream error;
  std::stringstream fatal;
  stan::callbacks::stream_logger logger(debug, info, warn, error, fatal);
  // We need an interrupt of some sort.
  stan::callbacks::interrupt interrupt;
  StructuredWriter init_writer = StructuredWriter();
  StructuredWriter parameter_writer = StructuredWriter();

  int seed = -1;
  if (opts->seed.is_some) {
    seed = opts->seed.val;
  } else {
    seed = std::chrono::system_clock::now().time_since_epoch().count();
  }

  // Create the data context.
  stan::io::array_var_context data_ctx = data_context(data);

  // Create a model.
  std::stringstream msg_stream;
  auto model = stan_model(data_ctx, seed, &msg_stream);

  // Create the init context.
  stan::io::array_var_context init_ctx = init_context(init);

  int return_code;
  // Default to the lbfgs algorithm.
  int algorithm = 2;
  if (opts->algorithm.is_some) {
    algorithm = opts->algorithm.val;
  }
  NewtonArgs n_args;
  LBFGSArgs args;
  // Run optimization.
  switch (algorithm) {
  case 0:
    return_code = stan::services::optimize::newton(
        model, init_ctx, n_args.seed, n_args.chain, n_args.init_radius,
        n_args.iter,
        false, // never save iterations.
        interrupt, logger, init_writer, parameter_writer);
    break;
  case 1:
    args = LBFGSArgs(opts);
    args.log(logger);
    return_code = stan::services::optimize::bfgs(
        model, init_ctx, args.seed, args.chain, args.init_radius,
        args.init_alpha, args.tol_obj, args.tol_rel_obj, args.tol_grad,
        args.tol_rel_grad, args.tol_param, args.iter,
        false, // never save iterations.
        args.refresh, interrupt, logger, init_writer, parameter_writer);
    break;
  case 2:
    args = LBFGSArgs(opts);
    args.log(logger);
    return_code = stan::services::optimize::lbfgs(
        model, init_ctx, args.seed, args.chain, args.init_radius,
        args.history_size, args.init_alpha, args.tol_obj, args.tol_rel_obj,
        args.tol_grad, args.tol_rel_grad, args.tol_param, args.iter,
        false, // never save iterations.
        args.refresh, interrupt, logger, init_writer, parameter_writer);
    break;
  }

  if (return_code != 0) {
    std::cerr << "optimization failed: " << return_code << std::endl;
    prophet_wasmstan_string_dup(err, error.str().c_str());
    return false;
  }

  // Read the names and values from the parameter stream and save to the
  // result.
  std::vector<std::string> names = parameter_writer.get_names();
  std::vector<std::vector<double>> values = parameter_writer.get_values();
  if (values.size() != 1) {
    prophet_wasmstan_string_set(err, "Expected 1 parameter vector");
    return false;
  }
  std::vector<double> params = values[0];
  if (params.size() != names.size()) {
    prophet_wasmstan_string_set(err,
                                "Expected names and values lengths to match");
    return false;
  }

  bool success = store_optimized_params(names, params, &ret->params, err);
  if (!success) {
    return false;
  }
  prophet_wasmstan_string_dup(&ret->logs.debug, debug.str().c_str());
  prophet_wasmstan_string_dup(&ret->logs.info, info.str().c_str());
  prophet_wasmstan_string_dup(&ret->logs.warn, warn.str().c_str());
  prophet_wasmstan_string_dup(&ret->logs.error, error.str().c_str());
  prophet_wasmstan_string_dup(&ret->logs.fatal, fatal.str().c_str());

  return true;
}

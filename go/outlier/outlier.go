// Code generated by arcjet-gravity; DO NOT EDIT.

// The outlier detector world.
package outlier

import "context"
import "errors"
import "github.com/tetratelabs/wazero"
import "github.com/tetratelabs/wazero/api"

import _ "embed"

//go:embed outlier.wasm
var wasmFileOutlier []byte

// Types used by the outlier detector world.
type IOutlierTypes interface {}

// A single outlier interval.
//
// An outlier interval is a contiguous range of indices in a time series
// where an outlier is detected.
type OutlierInterval struct {
	// The start index of the interval.
	Start uint32

	// The end index of the interval, if it exists.
	//
	// If the interval is open-ended, this will be `None`.
	End *uint32
}

// A potentially outlying series.
type Series struct {
	// Whether the series is an outlier for at least one of the samples.
	IsOutlier bool

	// The intervals of the samples that are considered outliers.
	OutlierIntervals []OutlierInterval

	// The outlier scores of the series for each sample.
	//
	// The higher the score, the more likely the series is an outlier.
	// Note that some implementations may not provide continuous scores
	// but rather a binary classification. In this case, the scores will
	// be 0.0 for non-outliers and 1.0 for outliers.
	Scores []float64
}

// A band indicating the min and max value considered outlying
// at each timestamp.
type Band struct {
	// The minimum value considered outlying at each timestamp.
	Min []float64

	// The maximum value considered outlying at each timestamp.
	Max []float64
}

// The output of an outlier detector
type Output struct {
	// The indexes of the series considered outliers.
	//
	// This is a `BTreeSet` to ensure that the order of the series is preserved.
	OutlyingSeries []uint32

	// The results of the detection for each series.
	SeriesResults []Series

	// The band indicating the min and max value considered outlying
	// at each timestamp.
	//
	// This may be `None` if no cluster was found (for example if
	// there were fewer than 3 series in the input data in the case of
	// DBSCAN).
	ClusterBand *Band
}

// Errors that can occur during outlier detection.
//
// Currently this is represented as a string because Gravity
// does not yet support more complex types.
type Error = string

// The epsilon or sensitivity parameter for the DBSCAN algorithm.
type EpsilonOrSensitivity interface {
	isEpsilonOrSensitivity()
}

// A scale-invariant sensitivity parameter.
//
// This must be in (0, 1) and will be used to estimate a sensible
// value of epsilon based on the data at detection-time.
type EpsilonOrSensitivitySensitivity float64
func (EpsilonOrSensitivitySensitivity) isEpsilonOrSensitivity() {}

// The maximum distance between points in a cluster.
type EpsilonOrSensitivityEpsilon float64
func (EpsilonOrSensitivityEpsilon) isEpsilonOrSensitivity() {}

// The parameters for the DBSCAN algorithm.
type DbscanParams struct {
	// Either the epsilon or sensitivity for the algorithm.
	EpsilonOrSensitivity EpsilonOrSensitivity
}

// Either a scale-invariant sensitivity parameter or a threshold.
type ThresholdOrSensitivity interface {
	isThresholdOrSensitivity()
}

// A scale-invariant sensitivity parameter.
//
// This must be in (0, 1) and will be used to estimate a sensible
// threshold at detection-time.
type ThresholdOrSensitivitySensitivity float64
func (ThresholdOrSensitivitySensitivity) isThresholdOrSensitivity() {}

// The threshold above which points are considered anomalous.
type ThresholdOrSensitivityThreshold float64
func (ThresholdOrSensitivityThreshold) isThresholdOrSensitivity() {}

// The parameters for the MAD algorithm.
type MadParams struct {
	// Either the threshold or sensitivity for the algorithm.
	ThresholdOrSensitivity ThresholdOrSensitivity
}

// The algorithm to use for outlier detection.
type Algorithm interface {
	isAlgorithm()
}

// The DBSCAN algorithm.
//
// This algorithm is a density-based algorithm that uses a
// clustering algorithm to group together points that are
// close to each other.
type AlgorithmDbscan DbscanParams
func (AlgorithmDbscan) isAlgorithm() {}

// The MAD algorithm.
//
// This algorithm is a density-based algorithm that uses a
// clustering algorithm to group together points that are
// close to each other.
type AlgorithmMad MadParams
func (AlgorithmMad) isAlgorithm() {}

// The input for the outlier detector.
//
// Currently this is represented as a string because Gravity
// does not yet support more complex types.
//
// It should be a JSON object with the following fields:
type Input struct {
	// The data to detect outliers in.
	Data [][]float64

	// The algorithm to use, with the params.
	Algorithm Algorithm
}

type OutlierFactory struct {
	runtime wazero.Runtime
	module wazero.CompiledModule
}

func NewOutlierFactory(
	ctx context.Context,
	types IOutlierTypes,
) (*OutlierFactory, error) {
	wazeroRuntime := wazero.NewRuntime(ctx)

	// Instantiate import host modules
	_, err0 := wazeroRuntime.NewHostModuleBuilder("grafana:augurs/types").
	Instantiate(ctx)
	if err0 != nil {
		return nil, err0
	}

	// Compiling the module takes a LONG time, so we want to do it once and hold
	// onto it with the Runtime
	module, err := wazeroRuntime.CompileModule(ctx, wasmFileOutlier)
	if err != nil {
		return nil, err
	}
	return &OutlierFactory{
		runtime: wazeroRuntime,
		module: module,
	}, nil
}

func (f *OutlierFactory) Instantiate(ctx context.Context) (*OutlierInstance, error) {
	if module, err := f.runtime.InstantiateModule(ctx, f.module, wazero.NewModuleConfig()); err != nil {
		return nil, err
	} else {
		return &OutlierInstance{module}, nil
	}
}

func (f *OutlierFactory) Close(ctx context.Context) {
	f.runtime.Close(ctx)
}

type OutlierInstance struct {
	module api.Module
}

func (i *OutlierInstance) Close(ctx context.Context) error {
	if err := i.module.Close(ctx); err != nil {
		return err
	}

	return nil
}

// writeString will put a Go string into the Wasm memory following the Component
// Model calling convetions, such as allocating memory with the realloc function
func writeString(
	ctx context.Context,
	s string,
	memory api.Memory,
	realloc api.Function,
) (uint64, uint64, error) {
	if len(s) == 0 {
		return 1, 0, nil
	}

	results, err := realloc.Call(ctx, 0, 0, 1, uint64(len(s)))
	if err != nil {
		return 1, 0, err
	}
	ptr := results[0]
	ok := memory.Write(uint32(ptr), []byte(s))
	if !ok {
		return 1, 0, err
	}
	return uint64(ptr), uint64(len(s)), nil
}

func (i *OutlierInstance) Detect(
	ctx context.Context,
	input Input,
) (Output, error) {
	arg0 := input
	// GetArg { nth: 0 }
	// RecordLower { record: Record { fields: [Field { name: "data", ty: Id(Id { idx: 16 }), docs: Docs { contents: Some("The data to detect outliers in.") } }, Field { name: "algorithm", ty: Id(Id { idx: 15 }), docs: Docs { contents: Some("The algorithm to use, with the params.") } }] }, name: "input", ty: Id { idx: 17 } }
	data0 := arg0.Data
	algorithm0 := arg0.Algorithm
	// ListLower { element: Id(Id { idx: 3 }), realloc: Some("cabi_realloc") }
	vec3 := data0
	len3 := uint64(len(vec3))
	result3, err3 := i.module.ExportedFunction("cabi_realloc").Call(ctx, 0, 0, 4, len3 * 8)
	if err3 != nil {
		var default3 Output
		return default3, err3
	}
	ptr3 := result3[0]
	for idx := uint64(0); idx < len3; idx++ {
		e := vec3[idx]
		base := uint32(ptr3 + uint64(idx) * uint64(8))
		// IterElem { element: Id(Id { idx: 3 }) }
		// IterBasePointer
		// ListLower { element: F64, realloc: Some("cabi_realloc") }
		vec2 := e
		len2 := uint64(len(vec2))
		result2, err2 := i.module.ExportedFunction("cabi_realloc").Call(ctx, 0, 0, 8, len2 * 8)
		if err2 != nil {
			var default2 Output
			return default2, err2
		}
		ptr2 := result2[0]
		for idx := uint64(0); idx < len2; idx++ {
			e := vec2[idx]
			base := uint32(ptr2 + uint64(idx) * uint64(8))
			// IterElem { element: F64 }
			// IterBasePointer
			// CoreF64FromF64
			result1 := api.EncodeF64(float64(e))
			// F64Store { offset: 0 }
			i.module.Memory().WriteUint64Le(uint32(base+0), result1)
		}
		// LengthStore { offset: ptrsz }
		i.module.Memory().WriteUint32Le(uint32(base+4), uint32(len2))
		// PointerStore { offset: 0 }
		i.module.Memory().WriteUint32Le(uint32(base+0), uint32(ptr2))
	}
	// VariantLower { variant: Variant { cases: [Case { name: "dbscan", ty: Some(Id(Id { idx: 12 })), docs: Docs { contents: Some("The DBSCAN algorithm.\n\nThis algorithm is a density-based algorithm that uses a\nclustering algorithm to group together points that are\nclose to each other.") } }, Case { name: "mad", ty: Some(Id(Id { idx: 14 })), docs: Docs { contents: Some("The MAD algorithm.\n\nThis algorithm is a density-based algorithm that uses a\nclustering algorithm to group together points that are\nclose to each other.") } }] }, name: "algorithm", ty: Id { idx: 15 }, results: [I32, I32, F64] }
	var variant12_0 uint64
	var variant12_1 uint64
	var variant12_2 uint64
	switch variantPayload := algorithm0.(type) {
		case AlgorithmDbscan:
			// VariantPayloadName
			// I32Const { val: 0 }
			// RecordLower { record: Record { fields: [Field { name: "epsilon-or-sensitivity", ty: Id(Id { idx: 11 }), docs: Docs { contents: Some("Either the epsilon or sensitivity for the algorithm.") } }] }, name: "dbscan-params", ty: Id { idx: 12 } }
			epsilonOrSensitivity4 := variantPayload.EpsilonOrSensitivity
			// VariantLower { variant: Variant { cases: [Case { name: "sensitivity", ty: Some(F64), docs: Docs { contents: Some("A scale-invariant sensitivity parameter.\n\nThis must be in (0, 1) and will be used to estimate a sensible\nvalue of epsilon based on the data at detection-time.") } }, Case { name: "epsilon", ty: Some(F64), docs: Docs { contents: Some("The maximum distance between points in a cluster.") } }] }, name: "epsilon-or-sensitivity", ty: Id { idx: 11 }, results: [I32, F64] }
			var variant7_0 uint64
			var variant7_1 uint64
			switch variantPayload := epsilonOrSensitivity4.(type) {
				case EpsilonOrSensitivitySensitivity:
					// VariantPayloadName
					// I32Const { val: 0 }
					// CoreF64FromF64
					result5 := api.EncodeF64(float64(variantPayload))
					variant7_0 = 0
					variant7_1 = result5
				case EpsilonOrSensitivityEpsilon:
					// VariantPayloadName
					// I32Const { val: 1 }
					// CoreF64FromF64
					result6 := api.EncodeF64(float64(variantPayload))
					variant7_0 = 1
					variant7_1 = result6
				default:
					var default7 Output
					return default7, errors.New("invalid variant type provided")
			}
			variant12_0 = 0
			variant12_1 = variant7_0
			variant12_2 = variant7_1
		case AlgorithmMad:
			// VariantPayloadName
			// I32Const { val: 1 }
			// RecordLower { record: Record { fields: [Field { name: "threshold-or-sensitivity", ty: Id(Id { idx: 13 }), docs: Docs { contents: Some("Either the threshold or sensitivity for the algorithm.") } }] }, name: "mad-params", ty: Id { idx: 14 } }
			thresholdOrSensitivity8 := variantPayload.ThresholdOrSensitivity
			// VariantLower { variant: Variant { cases: [Case { name: "sensitivity", ty: Some(F64), docs: Docs { contents: Some("A scale-invariant sensitivity parameter.\n\nThis must be in (0, 1) and will be used to estimate a sensible\nthreshold at detection-time.") } }, Case { name: "threshold", ty: Some(F64), docs: Docs { contents: Some("The threshold above which points are considered anomalous.") } }] }, name: "threshold-or-sensitivity", ty: Id { idx: 13 }, results: [I32, F64] }
			var variant11_0 uint64
			var variant11_1 uint64
			switch variantPayload := thresholdOrSensitivity8.(type) {
				case ThresholdOrSensitivitySensitivity:
					// VariantPayloadName
					// I32Const { val: 0 }
					// CoreF64FromF64
					result9 := api.EncodeF64(float64(variantPayload))
					variant11_0 = 0
					variant11_1 = result9
				case ThresholdOrSensitivityThreshold:
					// VariantPayloadName
					// I32Const { val: 1 }
					// CoreF64FromF64
					result10 := api.EncodeF64(float64(variantPayload))
					variant11_0 = 1
					variant11_1 = result10
				default:
					var default11 Output
					return default11, errors.New("invalid variant type provided")
			}
			variant12_0 = 1
			variant12_1 = variant11_0
			variant12_2 = variant11_1
		default:
			var default12 Output
			return default12, errors.New("invalid variant type provided")
	}
	// CallWasm { name: "detect", sig: WasmSignature { params: [Pointer, Length, I32, I32, F64], results: [Pointer], indirect_params: false, retptr: true } }
	raw13, err13 := i.module.ExportedFunction("detect").Call(ctx, uint64(ptr3), uint64(len3), uint64(variant12_0), uint64(variant12_1), uint64(variant12_2))
	if err13 != nil {
		var default13 Output
		return default13, err13
	}

	// The cleanup via `cabi_post_*` cleans up the memory in the guest. By
	// deferring this, we ensure that no memory is corrupted before the function
	// is done accessing it.
	defer func() {
		if _, err := i.module.ExportedFunction("cabi_post_detect").Call(ctx, raw13...); err != nil {
			// If we get an error during cleanup, something really bad is
			// going on, so we panic. Also, you can't return the error from
			// the `defer`
			panic(errors.New("failed to cleanup"))
		}
	}()

	results13 := raw13[0]
	// I32Load8U { offset: 0 }
	value14, ok14 := i.module.Memory().ReadByte(uint32(results13 + 0))
	if !ok14 {
		var default14 Output
		return default14, errors.New("failed to read byte from memory")
	}
	// ResultLift { result: Result_ { ok: Some(Id(Id { idx: 19 })), err: Some(String) }, ty: Id { idx: 20 } }
	var value58 Output
	var err58 error
	switch value14 {
	case 0:
		// PointerLoad { offset: ptrsz }
		ptr15, ok15 := i.module.Memory().ReadUint32Le(uint32(results13 + 4))
		if !ok15 {
			var default15 Output
			return default15, errors.New("failed to read pointer from memory")
		}
		// LengthLoad { offset: (2*ptrsz) }
		len16, ok16 := i.module.Memory().ReadUint32Le(uint32(results13 + 8))
		if !ok16 {
			var default16 Output
			return default16, errors.New("failed to read length from memory")
		}
		// ListLift { element: U32, ty: Id { idx: 6 } }
		base19 := ptr15
		len19 := len16
		result19 := make([]uint32, len19)
		for idx19 := uint32(0); idx19 < len19; idx19++ {
			base := base19 + idx19 * 4
			// IterBasePointer
			// I32Load { offset: 0 }
			value17, ok17 := i.module.Memory().ReadUint32Le(uint32(base + 0))
			if !ok17 {
				var default17 Output
				return default17, errors.New("failed to read i32 from memory")
			}
			// U32FromI32
			result18 := api.DecodeU32(uint64(value17))
			result19[idx19] = result18
		}
		// PointerLoad { offset: (3*ptrsz) }
		ptr20, ok20 := i.module.Memory().ReadUint32Le(uint32(results13 + 12))
		if !ok20 {
			var default20 Output
			return default20, errors.New("failed to read pointer from memory")
		}
		// LengthLoad { offset: (4*ptrsz) }
		len21, ok21 := i.module.Memory().ReadUint32Le(uint32(results13 + 16))
		if !ok21 {
			var default21 Output
			return default21, errors.New("failed to read length from memory")
		}
		// ListLift { element: Id(Id { idx: 4 }), ty: Id { idx: 7 } }
		base40 := ptr20
		len40 := len21
		result40 := make([]Series, len40)
		for idx40 := uint32(0); idx40 < len40; idx40++ {
			base := base40 + idx40 * 20
			// IterBasePointer
			// I32Load8U { offset: 0 }
			value22, ok22 := i.module.Memory().ReadByte(uint32(base + 0))
			if !ok22 {
				var default22 Output
				return default22, errors.New("failed to read byte from memory")
			}
			// BoolFromI32
			value23 := value22 != 0
			// PointerLoad { offset: ptrsz }
			ptr24, ok24 := i.module.Memory().ReadUint32Le(uint32(base + 4))
			if !ok24 {
				var default24 Output
				return default24, errors.New("failed to read pointer from memory")
			}
			// LengthLoad { offset: (2*ptrsz) }
			len25, ok25 := i.module.Memory().ReadUint32Le(uint32(base + 8))
			if !ok25 {
				var default25 Output
				return default25, errors.New("failed to read length from memory")
			}
			// ListLift { element: Id(Id { idx: 1 }), ty: Id { idx: 2 } }
			base33 := ptr24
			len33 := len25
			result33 := make([]OutlierInterval, len33)
			for idx33 := uint32(0); idx33 < len33; idx33++ {
				base := base33 + idx33 * 12
				// IterBasePointer
				// I32Load { offset: 0 }
				value26, ok26 := i.module.Memory().ReadUint32Le(uint32(base + 0))
				if !ok26 {
					var default26 Output
					return default26, errors.New("failed to read i32 from memory")
				}
				// U32FromI32
				result27 := api.DecodeU32(uint64(value26))
				// I32Load8U { offset: 4 }
				value28, ok28 := i.module.Memory().ReadByte(uint32(base + 4))
				if !ok28 {
					var default28 Output
					return default28, errors.New("failed to read byte from memory")
				}
				// OptionLift { payload: U32, ty: Id { idx: 0 } }
				var result31 uint32
				var ok31 bool
				if value28 == 0 {
					ok31 = false
				} else {
					// I32Load { offset: 8 }
					value29, ok29 := i.module.Memory().ReadUint32Le(uint32(base + 8))
					if !ok29 {
						var default29 Output
						return default29, errors.New("failed to read i32 from memory")
					}
					// U32FromI32
					result30 := api.DecodeU32(uint64(value29))
					ok31 = true
					result31 = result30
				}
				// RecordLift { record: Record { fields: [Field { name: "start", ty: U32, docs: Docs { contents: Some("The start index of the interval.") } }, Field { name: "end", ty: Id(Id { idx: 0 }), docs: Docs { contents: Some("The end index of the interval, if it exists.\n\nIf the interval is open-ended, this will be `None`.") } }] }, name: "outlier-interval", ty: Id { idx: 1 } }
				var ptr32x1 *uint32
				if ok31 {
					ptr32x1 = &result31
				} else {
					ptr32x1 = nil
				}
				value32 := OutlierInterval{
					Start: result27,
					End: ptr32x1,
				}
				result33[idx33] = value32
			}
			// PointerLoad { offset: (3*ptrsz) }
			ptr34, ok34 := i.module.Memory().ReadUint32Le(uint32(base + 12))
			if !ok34 {
				var default34 Output
				return default34, errors.New("failed to read pointer from memory")
			}
			// LengthLoad { offset: (4*ptrsz) }
			len35, ok35 := i.module.Memory().ReadUint32Le(uint32(base + 16))
			if !ok35 {
				var default35 Output
				return default35, errors.New("failed to read length from memory")
			}
			// ListLift { element: F64, ty: Id { idx: 3 } }
			base38 := ptr34
			len38 := len35
			result38 := make([]float64, len38)
			for idx38 := uint32(0); idx38 < len38; idx38++ {
				base := base38 + idx38 * 8
				// IterBasePointer
				// F64Load { offset: 0 }
				value36, ok36 := i.module.Memory().ReadUint64Le(uint32(base + 0))
				if !ok36 {
					var default36 Output
					return default36, errors.New("failed to read f64 from memory")
				}
				// F64FromCoreF64
				result37 := api.DecodeF64(value36)
				result38[idx38] = result37
			}
			// RecordLift { record: Record { fields: [Field { name: "is-outlier", ty: Bool, docs: Docs { contents: Some("Whether the series is an outlier for at least one of the samples.") } }, Field { name: "outlier-intervals", ty: Id(Id { idx: 2 }), docs: Docs { contents: Some("The intervals of the samples that are considered outliers.") } }, Field { name: "scores", ty: Id(Id { idx: 3 }), docs: Docs { contents: Some("The outlier scores of the series for each sample.\n\nThe higher the score, the more likely the series is an outlier.\nNote that some implementations may not provide continuous scores\nbut rather a binary classification. In this case, the scores will\nbe 0.0 for non-outliers and 1.0 for outliers.") } }] }, name: "series", ty: Id { idx: 4 } }
			value39 := Series{
				IsOutlier: value23,
				OutlierIntervals: result33,
				Scores: result38,
			}
			result40[idx40] = value39
		}
		// I32Load8U { offset: (5*ptrsz) }
		value41, ok41 := i.module.Memory().ReadByte(uint32(results13 + 20))
		if !ok41 {
			var default41 Output
			return default41, errors.New("failed to read byte from memory")
		}
		// OptionLift { payload: Id(Id { idx: 5 }), ty: Id { idx: 8 } }
		var result53 Band
		var ok53 bool
		if value41 == 0 {
			ok53 = false
		} else {
			// PointerLoad { offset: (6*ptrsz) }
			ptr42, ok42 := i.module.Memory().ReadUint32Le(uint32(results13 + 24))
			if !ok42 {
				var default42 Output
				return default42, errors.New("failed to read pointer from memory")
			}
			// LengthLoad { offset: (7*ptrsz) }
			len43, ok43 := i.module.Memory().ReadUint32Le(uint32(results13 + 28))
			if !ok43 {
				var default43 Output
				return default43, errors.New("failed to read length from memory")
			}
			// ListLift { element: F64, ty: Id { idx: 3 } }
			base46 := ptr42
			len46 := len43
			result46 := make([]float64, len46)
			for idx46 := uint32(0); idx46 < len46; idx46++ {
				base := base46 + idx46 * 8
				// IterBasePointer
				// F64Load { offset: 0 }
				value44, ok44 := i.module.Memory().ReadUint64Le(uint32(base + 0))
				if !ok44 {
					var default44 Output
					return default44, errors.New("failed to read f64 from memory")
				}
				// F64FromCoreF64
				result45 := api.DecodeF64(value44)
				result46[idx46] = result45
			}
			// PointerLoad { offset: (8*ptrsz) }
			ptr47, ok47 := i.module.Memory().ReadUint32Le(uint32(results13 + 32))
			if !ok47 {
				var default47 Output
				return default47, errors.New("failed to read pointer from memory")
			}
			// LengthLoad { offset: (9*ptrsz) }
			len48, ok48 := i.module.Memory().ReadUint32Le(uint32(results13 + 36))
			if !ok48 {
				var default48 Output
				return default48, errors.New("failed to read length from memory")
			}
			// ListLift { element: F64, ty: Id { idx: 3 } }
			base51 := ptr47
			len51 := len48
			result51 := make([]float64, len51)
			for idx51 := uint32(0); idx51 < len51; idx51++ {
				base := base51 + idx51 * 8
				// IterBasePointer
				// F64Load { offset: 0 }
				value49, ok49 := i.module.Memory().ReadUint64Le(uint32(base + 0))
				if !ok49 {
					var default49 Output
					return default49, errors.New("failed to read f64 from memory")
				}
				// F64FromCoreF64
				result50 := api.DecodeF64(value49)
				result51[idx51] = result50
			}
			// RecordLift { record: Record { fields: [Field { name: "min", ty: Id(Id { idx: 3 }), docs: Docs { contents: Some("The minimum value considered outlying at each timestamp.") } }, Field { name: "max", ty: Id(Id { idx: 3 }), docs: Docs { contents: Some("The maximum value considered outlying at each timestamp.") } }] }, name: "band", ty: Id { idx: 5 } }
			value52 := Band{
				Min: result46,
				Max: result51,
			}
			ok53 = true
			result53 = value52
		}
		// RecordLift { record: Record { fields: [Field { name: "outlying-series", ty: Id(Id { idx: 6 }), docs: Docs { contents: Some("The indexes of the series considered outliers.\n\nThis is a `BTreeSet` to ensure that the order of the series is preserved.") } }, Field { name: "series-results", ty: Id(Id { idx: 7 }), docs: Docs { contents: Some("The results of the detection for each series.") } }, Field { name: "cluster-band", ty: Id(Id { idx: 8 }), docs: Docs { contents: Some("The band indicating the min and max value considered outlying\nat each timestamp.\n\nThis may be `None` if no cluster was found (for example if\nthere were fewer than 3 series in the input data in the case of\nDBSCAN).") } }] }, name: "output", ty: Id { idx: 9 } }
		var ptr54x2 *Band
		if ok53 {
			ptr54x2 = &result53
		} else {
			ptr54x2 = nil
		}
		value54 := Output{
			OutlyingSeries: result19,
			SeriesResults: result40,
			ClusterBand: ptr54x2,
		}
		value58 = value54
	case 1:
		// PointerLoad { offset: ptrsz }
		ptr55, ok55 := i.module.Memory().ReadUint32Le(uint32(results13 + 4))
		if !ok55 {
			var default55 Output
			return default55, errors.New("failed to read pointer from memory")
		}
		// LengthLoad { offset: (2*ptrsz) }
		len56, ok56 := i.module.Memory().ReadUint32Le(uint32(results13 + 8))
		if !ok56 {
			var default56 Output
			return default56, errors.New("failed to read length from memory")
		}
		// StringLift
		buf57, ok57 := i.module.Memory().Read(ptr55, len56)
		if !ok57 {
			var default57 Output
			return default57, errors.New("failed to read bytes from memory")
		}
		str57 := string(buf57)
		err58 = errors.New(str57)
	default:
		err58 = errors.New("invalid variant discriminant for expected")
	}
	// Flush { amt: 1 }
	// Return { amt: 1, func: Function { name: "detect", kind: Freestanding, params: [("input", Id(Id { idx: 18 }))], result: Some(Id(Id { idx: 20 })), docs: Docs { contents: Some("Detect outliers in the input.") }, stability: Unknown } }
	return value58, err58
}
